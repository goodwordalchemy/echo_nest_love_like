{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, I wasn't able to load the data, so all of my work will be on the echo nest application repo.\n",
    "\n",
    "#Naive Bayes\n",
    "* naive because assumes independence between all features.\n",
    "    * comes from likelihood function when considering two features.\n",
    "* keeping track of which feature gives evidence to which class.\n",
    "\n",
    "* Laplace Smoothing - add one extra occurance in numerator and one for every feature in denominator to account for all the extra added ones.\n",
    "\n",
    "##Arithmetic Underflows\n",
    "* use log likelihoods/probabilities to change range from (0,1) to (-inf, 0).\n",
    "\n",
    "$$\n",
    "logP(C)*P(F_1|C)*P(F_2|C) = logP(C) + logP(F_1|C) + logP(F_2|C)\n",
    "$$\n",
    "\n",
    "##SKLearn package:\n",
    "`sklearn.naive_bayes`\n",
    "* GaussianNB - assumes features are normally distributed.  E.g. sex classification from height and width.\n",
    "* MultinomialNB - assumes features to be occurence counts.  (TF-IDF)\n",
    "* BernoulliNB - similar to Multinomial but better for testing boolean i.e. whether or not a word occurred.\n",
    "\n",
    "##How they do it\n",
    "1. filter out tweets with no sentiment to get binary  classification. (not on second run though.  \n",
    "    * incorporates multiple classes\n",
    "    * uses preprocessor for conjunctions and emoticons\n",
    "    * take into account part of speech vector for tweets.\n",
    "2. Convert raw tweets into TF-IDF feature values.\n",
    "3. Make pipeline with tf-idf and multinomialNB\n",
    "4. fit on ShuffleSplit, which resamples shuffled data\n",
    "5. collect scores and plot P/R curve\n",
    "\n",
    "###after initial run, tuning params:\n",
    "TfidfVectorizer:\n",
    "* different settings for Ngrams\n",
    "* min_df\n",
    "* use_idf or smooth_idf in TF-IDF\n",
    "* removing stop words\n",
    "* whether to use log word counts\n",
    "* track word counts or booleans\n",
    "\n",
    "MultinomialNB:\n",
    "* smoothing method by setting alpha\n",
    "    * add-one or laplace smoothing: 1\n",
    "    * Lidstone smoothing: 0.01, 0.05, 0.1, 0.5\n",
    "    * No smoothing.\n",
    "\n",
    "GridSEarchCV:\n",
    "* takes estimator arg (Pipeline in this case and dict of parameters)\n",
    "* interface: `<estimator>__<subestimator>__...__<param_name>: <list of values>`\n",
    "* cv parameter\n",
    "* score function is f1_score\n",
    "\n",
    "#Cleaning Tweets\n",
    "* emoticons\n",
    "* conjuntions\n",
    "* POS tagging - makes dependence tree.  NN for nouns, VB for verbs, JJ for adjectives, and RB for adverbs\n",
    "* SentiWordNet - POS, PosScore, NegScore (if occurs multiple times take average)\n",
    "* Feature Union class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
